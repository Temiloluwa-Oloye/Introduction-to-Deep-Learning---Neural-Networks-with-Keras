{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d11aed0d-b59c-4c15-b005-07f6f0e2f606",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0101EN-SkillsNetwork/images/IDSN-logo.png\" width=\"400\"> </a>\n",
    "\n",
    "# BackPropagation\n",
    "\n",
    "Estimated time needed: **30** mins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8783e34-0eec-49d3-834b-2f006f120380",
   "metadata": {},
   "source": [
    "Backpropagation is the key algorithm used for training neural networks, allowing them to learn from data. It is based on the gradient descent optimization technique and works by iteratively adjusting the weights and biases of the network to minimize the error between the predicted and actual outputs.\n",
    " In this lab, we will create a neural network to implement backpropagation for a XOR problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0ce3a9-1fbe-4d66-ba1f-dcad9a1605a1",
   "metadata": {},
   "source": [
    "# Objective for this notebook\n",
    "\n",
    "* Train a Neural Network to Solve the XOR Problem\n",
    "* Implement Backpropagation for Neural Network Training\n",
    "* Demonstrate the Use of Activation Functions\n",
    "* Understand the Learning Process Over Multiple Epochs\n",
    "* Demonstrate Weight and Bias Adjustments via Gradient Descent\n",
    "* Evaluate the Model's Performance After Training\n",
    "* Monitor and Analyze the Training Process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4491443-299b-4cee-88bf-168b3b7048e0",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 4>\n",
    "1. <a href=\"#Import-Required-Libraries\">Import Required Libraries</a><br>\n",
    "2. <a href=\"#Initialize-Inputs\">Initialize Inputs</a><br>\n",
    "3. <a href=\"#Declare-the-network-parameters\">Declare the network parameters</a><br>\n",
    "4. <a href=\"#Define-the-weights\">Define the weights</a><br>  \n",
    "5. <a href=\"#Training-the-Neural-Network\">Training the Neural Network</a><br>  \n",
    "6. <a href=\"#Testing-the-Network\">Testing the Network</a><br>  \n",
    "7. <a href=\"#Plot-the-error\">Plot the error</a><br>  \n",
    "\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c80e4ac-0092-4708-ab57-7930c763fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented. \n",
    "# If you run this notebook on a different environment, e.g., your desktop, you may need to uncomment and install certain libraries.\n",
    "\n",
    "#!pip install numpy==1.26.4\n",
    "#!pip install matplotlib==3.5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ae86ef-5f63-4eba-9513-87fa46a9f5a5",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\temiloluwa oloye\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\temiloluwa oloye\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\temiloluwa oloye\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\temiloluwa oloye\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\temiloluwa oloye\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\temiloluwa oloye\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\temiloluwa oloye\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\temiloluwa oloye\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\temiloluwa oloye\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\temiloluwa oloye\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\temiloluwa oloye\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\Temiloluwa Oloye\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\Temiloluwa Oloye\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\Temiloluwa Oloye\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fdbbe01-fb5f-445f-b0b2-c86b2e3c328a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _path: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importing the required library\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\__init__.py:174\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\rcsetup.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\colors.py:57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\scale.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[0;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[0;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\ticker.py:143\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[0;32m    145\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    147\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    148\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    149\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    156\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\transforms.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _path: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "# Importing the required library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692bf257-2f19-4617-8848-c4e1e4997dd8",
   "metadata": {},
   "source": [
    "## Initialize Inputs\n",
    "Define the input and expected output for a XOR gate problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2884ee5c-b824-4b74-a2b9-302e9d16ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining inputs and expected output (XOR truth table)\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]).T  # 2x4 matrix, each column is a training example\n",
    "d = np.array([0, 1, 1, 0])  # Expected output for XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb35b18-d061-481b-8147-f5618463b137",
   "metadata": {},
   "source": [
    "# Declare the network parameters & the weights\n",
    "\n",
    "Define the network parameters such as\n",
    "1. number of input neurons\n",
    "2. hidden layer neurons\n",
    "3. output neurons\n",
    "4. learning rate\n",
    "5. number of epochs\n",
    "\n",
    "Also, Declare the weights for the neurons. The initial weights are taken as random numbers which are then optimized by the backpropagation algorithm inside a function parameter `initialize_network_parameters()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f7ab1e-5f3d-49a8-80a0-bbbeca9ca791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network_parameters():\n",
    "    # Network parameters\n",
    "    inputSize = 2      # Number of input neurons (x1, x2)\n",
    "    hiddenSize = 2     # Number of hidden neurons\n",
    "    outputSize = 1     # Number of output neurons\n",
    "    lr = 0.1           # Learning rate\n",
    "    epochs = 180000    # Number of training epochs\n",
    "\n",
    "    # Initialize weights and biases randomly within the range [-1, 1]\n",
    "    w1 = np.random.rand(hiddenSize, inputSize) * 2 - 1  # Weights from input to hidden layer\n",
    "    b1 = np.random.rand(hiddenSize, 1) * 2 - 1          # Bias for hidden layer\n",
    "    w2 = np.random.rand(outputSize, hiddenSize) * 2 - 1 # Weights from hidden to output layer\n",
    "    b2 = np.random.rand(outputSize, 1) * 2 - 1          # Bias for output layer\n",
    "\n",
    "    return w1, b1, w2, b2, lr, epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c53ab7e-fdc8-491f-8003-574339488205",
   "metadata": {},
   "source": [
    "## Training the Neural Network\n",
    "\n",
    "The neural network works in 5 stages: \n",
    "1. Forward pass\n",
    "    * The input **X** is multiplied by the weights **w1** and passed through the first layer, followed by the application of the sigmoid or ReLU activation function. This gives the output for the hidden layer.\n",
    "    * The output of the hidden layer is then passed through the second set of weights **w2** to compute the final output. Again, a sigmoid activation function is used to generate the final output **a2**.\n",
    "    \n",
    "2. Error calculation\n",
    "    * The error is computed as the difference between the expected output **(d)** and the actual output **(a2)**.\n",
    "3. Backward pass\n",
    "    * **Output Layer**: The derivative of the sigmoid activation function is applied to the error, producing the gradient for the output layer **(da2)**. This is used to calculate how much the weights in the output layer need to be adjusted.\n",
    "    * **Hidden Layer**: The error is then propagated backward to the hidden layer. The gradient at the hidden layer **(da1)** is computed by taking the dot product of the transpose of the weights **(w2.T)** and the gradient from the output layer. The derivative of the activation function (sigmoid or ReLU) is used to adjust this error.\n",
    "4. Weights and bias updates\n",
    "    * After computing the **gradients (dz1, dz2)**, the **weights (w1, w2)** and **biases (b1, b2)** are updated using the **learning rate (lr)** and **the gradients**. The updates are done to minimize the error and improve the model’s predictions.\n",
    "5. Training:\n",
    "    * This entire process is repeated over many iterations **(epochs)**. During each epoch, the model adjusts its weights and biases to reduce the error. Over time, the network learns to approximate the XOR function.\n",
    "Forward Pass:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725d6508-acf1-41c6-a2f5-85ad478979d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get initialized parameters\n",
    "w1, b1, w2, b2, lr, epochs = initialize_network_parameters()\n",
    "\n",
    "# Training the network using backpropagation\n",
    "error_list = []\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(w1, X) + b1  # Weighted sum for hidden layer\n",
    "    a1 = 1 / (1 + np.exp(-z1))  # Sigmoid activation for hidden layer\n",
    "\n",
    "    z2 = np.dot(w2, a1) + b2  # Weighted sum for output layer\n",
    "    a2 = 1 / (1 + np.exp(-z2))  # Sigmoid activation for output layer\n",
    "\n",
    "    # Error calculation and backpropagation\n",
    "    error = d - a2  # Difference between expected and actual output\n",
    "    da2 = error * (a2 * (1 - a2))  # Derivative for output layer\n",
    "    dz2 = da2  # Gradient for output layer\n",
    "\n",
    "    # Propagate error to hidden layer\n",
    "    da1 = np.dot(w2.T, dz2)  # Gradient for hidden layer\n",
    "    dz1 = da1 * (a1 * (1 - a1))  # Derivative for hidden layer\n",
    "\n",
    "    # Update weights and biases\n",
    "    w2 += lr * np.dot(dz2, a1.T)  # Update weights from hidden to output layer\n",
    "    b2 += lr * np.sum(dz2, axis=1, keepdims=True)  # Update bias for output layer\n",
    "\n",
    "    w1 += lr * np.dot(dz1, X.T)  # Update weights from input to hidden layer\n",
    "    b1 += lr * np.sum(dz1, axis=1, keepdims=True)  # Update bias for hidden layer\n",
    "    if (epoch+1)%10000 == 0:\n",
    "        print(\"Epoch: %d, Average error: %0.05f\"%(epoch, np.average(abs(error))))\n",
    "        error_list.append(np.average(abs(error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d09c8ca-d1b7-4161-9d11-f6d0b383ddc3",
   "metadata": {},
   "source": [
    "## Testing the Network\n",
    "After training, you can now test the neural network to verify that it has learned the XOR function and outputs the correct values close to [0, 1, 1, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5021c41-be38-41b8-9782-7234c93267d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the trained network\n",
    "z1 = np.dot(w1, X) + b1  # Weighted sum for hidden layer\n",
    "a1 = 1 / (1 + np.exp(-z1))  # Sigmoid activation for hidden layer\n",
    "\n",
    "z2 = np.dot(w2, a1) + b2  # Weighted sum for output layer\n",
    "a2 = 1 / (1 + np.exp(-z2))  # Sigmoid activation for output layer\n",
    "\n",
    "# Print results\n",
    "print('Final output after training:', a2)\n",
    "print('Ground truth', d)\n",
    "print('Error after training:', error)\n",
    "print('Average error: %0.05f'%np.average(abs(error)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495deff4-45c7-4867-953a-1cbbf99688c2",
   "metadata": {},
   "source": [
    "## Plot the error\n",
    "Here, we plot the error as a function of epochs. This shows how error changed over multiple iterations of forward and backward passes and how the network learnt over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183e6c1-9f03-4849-8a8e-941a490590c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error\n",
    "plt.plot(error_list)\n",
    "plt.title('Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f7b2a-eba6-4f46-8499-b8de40299f8e",
   "metadata": {},
   "source": [
    "# Practice exercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34a5bf-00be-47c8-9568-b07eb3b5d1e2",
   "metadata": {},
   "source": [
    "Implement backpropagation for **AND problem** using similar input as used for XOR problem above and plot the error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ae094-9191-4c6b-bb00-946c7b16268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa003fa3-61a9-4d23-8718-3f553c2f7dd0",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]).T  # 2x4 matrix, each column is a training example\n",
    "d = np.array([0, 0, 0, 1])  # Expected output for AND\n",
    "\n",
    "# Get initialized parameters\n",
    "w1, b1, w2, b2, lr, epochs = initialize_network_parameters()\n",
    "\n",
    "# Training the network using backpropagation\n",
    "error_list = []\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(w1, X) + b1  # Weighted sum for hidden layer\n",
    "    a1 = 1 / (1 + np.exp(-z1))  # Sigmoid activation for hidden layer\n",
    "\n",
    "    z2 = np.dot(w2, a1) + b2  # Weighted sum for output layer\n",
    "    a2 = 1 / (1 + np.exp(-z2))  # Sigmoid activation for output layer\n",
    "\n",
    "    # Error calculation and backpropagation\n",
    "    error = d - a2  # Difference between expected and actual output\n",
    "    da2 = error * (a2 * (1 - a2))  # Derivative for output layer\n",
    "    dz2 = da2  # Gradient for output layer\n",
    "\n",
    "    # Propagate error to hidden layer\n",
    "    da1 = np.dot(w2.T, dz2)  # Gradient for hidden layer\n",
    "    dz1 = da1 * (a1 * (1 - a1))  # Derivative for hidden layer\n",
    "\n",
    "    # Update weights and biases\n",
    "    w2 += lr * np.dot(dz2, a1.T)  # Update weights from hidden to output layer\n",
    "    b2 += lr * np.sum(dz2, axis=1, keepdims=True)  # Update bias for output layer\n",
    "\n",
    "    w1 += lr * np.dot(dz1, X.T)  # Update weights from input to hidden layer\n",
    "    b1 += lr * np.sum(dz1, axis=1, keepdims=True)  # Update bias for hidden layer\n",
    "    if (epoch+1)%10000 == 0:\n",
    "        print(\"Epoch: %d, Average error: %0.05f\"%(epoch, np.average(abs(error))))\n",
    "        error_list.append(np.average(abs(error)))\n",
    "\n",
    "\n",
    "# Testing the trained network\n",
    "z1 = np.dot(w1, X) + b1  # Weighted sum for hidden layer\n",
    "a1 = 1 / (1 + np.exp(-z1))  # Sigmoid activation for hidden layer\n",
    "\n",
    "z2 = np.dot(w2, a1) + b2  # Weighted sum for output layer\n",
    "a2 = 1 / (1 + np.exp(-z2))  # Sigmoid activation for output layer\n",
    "\n",
    "# Print results\n",
    "print('\\nFinal output after training:', a2)\n",
    "print('Ground truth', d)\n",
    "print('Error after training:', error)\n",
    "print('Average error: %0.05f'%np.average(abs(error)))\n",
    "\n",
    "# Plot error\n",
    "plt.plot(error_list)\n",
    "plt.title('Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404168b4-fa14-4e5b-afac-a89d2ffe3a5c",
   "metadata": {},
   "source": [
    "# Practice exercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56772158-659c-4d2c-ba08-186cc2ae25bb",
   "metadata": {},
   "source": [
    "Now, decrease the learning rate to 0.01 and increase the number of epochs to 1000000 and check the error for XOR gate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc3a30-165f-4067-a8cc-003598464b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca0138-81af-4563-b17d-4636d98b7e7d",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "lr = 0.01         # Learning rate\n",
    "epochs = 1000000   # Number of training epochs\n",
    "\n",
    "\n",
    "# Defining inputs and expected output (XOR truth table)\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]).T  # 2x4 matrix, each column is a training example\n",
    "d = np.array([0, 1, 1, 0])  # Expected output for XOR\n",
    "\n",
    "# Get initialized parameters\n",
    "w1, b1, w2, b2, lr, epochs = initialize_network_parameters()\n",
    "\n",
    "# Training the network using backpropagation\n",
    "error_list = []\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(w1, X) + b1  # Weighted sum for hidden layer\n",
    "    a1 = 1 / (1 + np.exp(-z1))  # Sigmoid activation for hidden layer\n",
    "\n",
    "    z2 = np.dot(w2, a1) + b2  # Weighted sum for output layer\n",
    "    a2 = 1 / (1 + np.exp(-z2))  # Sigmoid activation for output layer\n",
    "\n",
    "    # Error calculation and backpropagation\n",
    "    error = d - a2  # Difference between expected and actual output\n",
    "    da2 = error * (a2 * (1 - a2))  # Derivative for output layer\n",
    "    dz2 = da2  # Gradient for output layer\n",
    "\n",
    "    # Propagate error to hidden layer\n",
    "    da1 = np.dot(w2.T, dz2)  # Gradient for hidden layer\n",
    "    dz1 = da1 * (a1 * (1 - a1))  # Derivative for hidden layer\n",
    "\n",
    "    # Update weights and biases\n",
    "    w2 += lr * np.dot(dz2, a1.T)  # Update weights from hidden to output layer\n",
    "    b2 += lr * np.sum(dz2, axis=1, keepdims=True)  # Update bias for output layer\n",
    "\n",
    "    w1 += lr * np.dot(dz1, X.T)  # Update weights from input to hidden layer\n",
    "    b1 += lr * np.sum(dz1, axis=1, keepdims=True)  # Update bias for hidden layer\n",
    "    if (epoch+1)%10000 == 0:\n",
    "        print(\"Epoch: %d, Average error: %0.05f\"%(epoch, np.average(abs(error))))\n",
    "        error_list.append(np.average(abs(error)))\n",
    "\n",
    "\n",
    "# Testing the trained network\n",
    "z1 = np.dot(w1, X) + b1  # Weighted sum for hidden layer\n",
    "a1 = 1 / (1 + np.exp(-z1))  # Sigmoid activation for hidden layer\n",
    "\n",
    "z2 = np.dot(w2, a1) + b2  # Weighted sum for output layer\n",
    "a2 = 1 / (1 + np.exp(-z2))  # Sigmoid activation for output layer\n",
    "\n",
    "# Print results\n",
    "print('\\nFinal output after training:', a2)\n",
    "print('Ground truth', d)\n",
    "print('Error after training:', error)\n",
    "print('Average error: %0.05f'%np.average(abs(error)))\n",
    "\n",
    "\n",
    "# Plot error\n",
    "plt.plot(error_list)\n",
    "plt.title('Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc00c6de-77f2-4146-9f95-10724a1cceb7",
   "metadata": {},
   "source": [
    "## Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by [Aman Aggarwal](https://www.linkedin.com/in/aggarwal-aman/). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342eafa8-2a53-4841-bc11-447674655b81",
   "metadata": {},
   "source": [
    "\n",
    "<!--\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2024-11-20  | 1.0  | Aman  |  Created the lab |\n",
    "<hr>\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73e74f8-e016-4977-b5c7-7607589c88dc",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "prev_pub_hash": "23c643c8c1aa843c3873f66d020bff9ca5df91f975ec512e5214e2cad5adc399"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
